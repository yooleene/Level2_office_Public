{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>M5_종합실습</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.정형(테이블) 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터 원본 종류별 적용 패키지\n",
    "- CSV : pandas\n",
    "- 웹 사이트 데이터 : selenium + bs4 + Pandas\n",
    "\n",
    "> 최종 결과 데이터 형태 : Pandas DataFrame \n",
    "- 데이터를 가져오면,\n",
    "- 데이터 프레임 형태의 데이터가 결과물로 반환 되는데,\n",
    "- 이후, 결과 데이터를 활용하여 통계 작업 등에 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) CSV 파일 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터셋 : data_set/sample_table.csv (공공데이터포털 - 과학기술정보통신부 중앙전파관리소_국내외 신규위성 발사 현황_20230930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_set/sample_table.csv', encoding='euc-kr')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 웹 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터셋 : http://new-collar.kr/data_set/sample_table.html (공공데이터포털 - 과학기술정보통신부 중앙전파관리소_국내외 신규위성 발사 현황_20230930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://new-collar.kr/data_set/sample_table.html'\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "soup = bs(driver.page_source, 'html.parser')\n",
    "\n",
    "table = '#personal_profile' # id값으로 가져오기\n",
    "info = soup.select(table) # select로 가져오기\n",
    "\n",
    "table = pd.read_html(str(info)) # pd.read_html으로 읽기 위해 str로 변환\n",
    "df = table[0] # 리스트 형식의 table 내에 데이터 프레임 1개만 존재하여 table[0]으로 추출\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.정형(테이블) 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기본 정보 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기본 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 총 발사실패 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['발사실패'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 항목별 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=0, numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 년도별 발사 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['년도'] = df['연월일'].str[:4] # '년도'만 추출하여 열 추가\n",
    "df.groupby('년도')['정지위성'].sum() # '년도'로 그룹화하여 '정지위성' 합계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.비정형(텍스트) 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 텍스트 파일 가져오기 - read()를 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터셋 :  data_set/sample_text.txt  (wikipedia.org - Society)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data_set/sample_text.txt', 'r', encoding='utf-8') \n",
    "raw = f.read() # 모든 텍스트를 텍스트 형식으로 반환\n",
    "raw[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 형식 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자열 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 텍스트 파일 가져오기 - readlines()를 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터셋 : data_set/sample_text.txt  (wikipedia.org - Society)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data_set/sample_text.txt', 'r', encoding='utf-8') \n",
    "raw = f.readlines() # 개행문자를 기준으로 라인 단위 리스트 형식로 반환\n",
    "print(raw[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 형식 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자열 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_str = 0\n",
    "\n",
    "for r in raw:\n",
    "    len_str += len(r)\n",
    "len_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 웹 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터셋 : http://new-collar.kr/data_set/sample_text.html  (wikipedia.org - Society)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "url = 'http://new-collar.kr/data_set/sample_text.html'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "raw = driver.find_element(By.XPATH, '/html/body/main/div[2]/div/p[2]').text # 텍스트만 추출\n",
    "raw[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 형식 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자열 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw) # 텍스트 파일과 웹 데이터 추출 데이터의 길이가 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 한글 텍스트 파일 가져오기 - read()를 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터셋 :  : data_set/sample_text_ko.txt  (wikipedia.org - 사회)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data_set/sample_text_ko.txt', 'r', encoding='utf-8') \n",
    "raw_ko = f.read() # 모든 텍스트를 텍스트 형식으로 반환\n",
    "raw_ko[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 형식 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw_ko)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자열 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_ko)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.비정형(텍스트) 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 키워드 빈도 분석(한글)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 형태소 분석(토큰화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from kiwipiepy.utils import Stopwords\n",
    "\n",
    "kiwi = Kiwi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = kiwi.tokenize(raw_ko)\n",
    "print(tokens[:10])\n",
    "print(len(tokens)) # 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 키워드(단어)만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = kiwi.tokenize(raw_ko)\n",
    "token_text = []\n",
    "\n",
    "for token in tokens:\n",
    "    token_text.append(token.form) # 형태소만 append\n",
    "      \n",
    "print(token_text[:100])\n",
    "print(len(token_text)) # 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = kiwi.tokenize(raw_ko)\n",
    "token_text = []\n",
    "\n",
    "for token in tokens:\n",
    "    if token.tag[0] == 'N': # 명사인 경우만\n",
    "        token_text.append(token.form) #형태소만 append\n",
    "      \n",
    "print(token_text[:100])\n",
    "print(len(token_text)) # 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어 제거 : kiwipiepy 내장 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = Stopwords()\n",
    "\n",
    "tokens = kiwi.tokenize(raw_ko, stopwords=stopwords) # 내장 불용어 제외 후 토큰화\n",
    "print(tokens[:10])\n",
    "print(len(tokens)) # 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어 제거 : 사용자 정의 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stop = ['사회', '영어']\n",
    "\n",
    "tokens = kiwi.tokenize(raw_ko)\n",
    "token_text = []\n",
    "\n",
    "for token in tokens:\n",
    "    if token.form not in user_stop: # 형태소가 불용어가 아니라면\n",
    "        token_text.append(token.form) # 형태소만 append\n",
    "      \n",
    "print(token_text[:100])\n",
    "print(len(token_text)) # 토큰 갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 조건 적용 : 명사만, 내장+사용자 정의 불용어 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = Stopwords()\n",
    "user_stop = ['사회', '영어']\n",
    "\n",
    "tokens = kiwi.tokenize(raw_ko, stopwords=stopwords) # 내장 불용어 제외 후 토큰화\n",
    "token_text = []\n",
    "\n",
    "for token in tokens:\n",
    "    if (token.tag[0] == 'N') & (token.form not in user_stop): # 명사만, 사용자 불용어 제외\n",
    "        token_text.append(token.form) #형태소만 append\n",
    "      \n",
    "print(token_text[:100])\n",
    "print(len(token_text)) # 토큰 갯수 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 단어 빈도수 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nnOU6NDTWM9"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(token_text)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 빈도수 높은 10개 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_c = c.most_common(10) \n",
    "print(top_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) BoW로 빈도 분석(영어)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 텍스트 파일에서 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data_set/sample_text.txt', 'r', encoding='utf-8') \n",
    "raw = f.read() # 모든 텍스트를 텍스트 형식으로 반환\n",
    "print(type(raw))\n",
    "print(raw[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BoW 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 내장 불용어 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(stop_words='english')\n",
    "\n",
    "text = [raw] # 리스트 형식으로 변환\n",
    "bow = vector.fit_transform(text)\n",
    "\n",
    "print(vector.get_feature_names_out()) # 토큰화된 단어 목록 확인\n",
    "print(bow.toarray()) # 배열 형태로 빈도수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용자 불용어 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "user_stop = ['000', '01']\n",
    "vector = CountVectorizer(stop_words=user_stop)\n",
    "\n",
    "text = [raw] # 리스트 형식으로 변환\n",
    "bow = vector.fit_transform(text)\n",
    "\n",
    "print(vector.get_feature_names_out()) # 토큰화된 단어 목록 확인\n",
    "print(bow.toarray()) # 배열 형태로 빈도수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 내장+사용자 불용어 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장 불용어 확인\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(stop_words='english')\n",
    "print(vector.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장 불용어를 리스트로 변환\n",
    "s_w = list(vector.get_stop_words())\n",
    "print(s_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장 불용어(stopwords)에 사용자 불용어(user_stop) 추가\n",
    "\n",
    "s_w.extend(user_stop)\n",
    "print(s_w)\n",
    "\n",
    "vector = CountVectorizer(stop_words=s_w)\n",
    "bow = vector.fit_transform(text)\n",
    "\n",
    "print(vector.get_feature_names_out()) # 토큰화된 단어 목록 확인\n",
    "print(bow.toarray()) # 배열 형태로 빈도수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DTM에서 키워드별 빈도수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# columns = []\n",
    "# for k, v in sorted(vector.vocabulary_.items(), key=lambda item:item[1]):\n",
    "#       columns.append(k)\n",
    "\n",
    "# df = pd.DataFrame(bow.toarray(), columns=columns)\n",
    "\n",
    "df = pd.DataFrame(bow.toarray(), columns=vector.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=0, axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 10개 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=0, axis=1, ascending=False).iloc[:,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 키워드별 인덱스 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인덱스로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vector.vocabulary_\n",
    "sorted(vocab.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 키워드로 인덱스 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['technology', '15', '2000']\n",
    "value = []\n",
    "for k in key:\n",
    "    value.append(vector.vocabulary_[k])\n",
    "value "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a86e7cc0d3fd2b3984d90a12bd1fbcf5461ee2e2e08ec83f39bc9fc9adb9109f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
